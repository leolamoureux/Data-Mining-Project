{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Musicians to tackle US red tape\\n\\nMusicians' ...</td>\n",
       "      <td>Nigel McCune from the Musicians' Union said Br...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U2's desire to be number one\\n\\nU2, who have w...</td>\n",
       "      <td>But they still want more.They have to want to ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rocker Doherty in on-stage fight\\n\\nRock singe...</td>\n",
       "      <td>Babyshambles, which he formed after his acrimo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snicket tops US box office chart\\n\\nThe film a...</td>\n",
       "      <td>A Series of Unfortunate Events also stars Scot...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ocean's Twelve raids box office\\n\\nOcean's Twe...</td>\n",
       "      <td>Ocean's Twelve, the crime caper sequel starrin...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  Musicians to tackle US red tape\\n\\nMusicians' ...   \n",
       "1  U2's desire to be number one\\n\\nU2, who have w...   \n",
       "2  Rocker Doherty in on-stage fight\\n\\nRock singe...   \n",
       "3  Snicket tops US box office chart\\n\\nThe film a...   \n",
       "4  Ocean's Twelve raids box office\\n\\nOcean's Twe...   \n",
       "\n",
       "                                             summary          topic  \n",
       "0  Nigel McCune from the Musicians' Union said Br...            NaN  \n",
       "1  But they still want more.They have to want to ...  entertainment  \n",
       "2  Babyshambles, which he formed after his acrimo...            NaN  \n",
       "3  A Series of Unfortunate Events also stars Scot...            NaN  \n",
       "4  Ocean's Twelve, the crime caper sequel starrin...  entertainment  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"BBC_df.csv\", encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'inputs avant suppression des textes non anglais : 2225\n",
      "Nombre d'inputs après suppression des textes non anglais : 2225\n"
     ]
    }
   ],
   "source": [
    "import langdetect\n",
    "\n",
    "def detect_language(text):\n",
    "    return langdetect.detect(text)\n",
    "\n",
    "df = pd.read_csv(\"BBC_df.csv\", encoding = \"ISO-8859-1\")\n",
    "print(\"Nombre d'inputs avant suppression des textes non anglais : \" + str(len(df)))\n",
    "\n",
    "# créer une liste vide qui contiendra les indices des lignes à supprimer\n",
    "indexes_to_delete = []\n",
    "\n",
    "# parcourir chaque ligne du dataframe\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    lang = detect_language(row['article'][0:200])\n",
    "    # si la valeur de l'attribut 'text' commence par un 'm'\n",
    "    if type(row[\"article\"]) == float:\n",
    "    # ajouter l'index de cette ligne à la liste des indices à supprimer\n",
    "        indexes_to_delete.append(index)\n",
    "\n",
    "# supprimer les lignes du dataframe en utilisant la liste des indices à supprimer\n",
    "df.drop(indexes_to_delete, inplace=True)\n",
    "\n",
    "print(\"Nombre d'inputs après suppression des textes non anglais : \" + str(len(df)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE PUNCTUATION\n",
    "import string\n",
    "\n",
    "def remove_punctuation(summary):\n",
    "    punctuationfree=\"\".join([i for i in summary if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "df[\"article\"] = df[\"article\"].apply(lambda row : remove_punctuation(row))\n",
    "df[\"article\"] = df[\"article\"].apply(lambda row: row.lower())\n",
    "\n",
    "df[\"summary\"] = df[\"summary\"].apply(lambda row : remove_punctuation(row))\n",
    "df[\"summary\"] = df[\"summary\"].apply(lambda row: row.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZATION\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df[\"article\"] = df[\"article\"].apply(lambda x : word_tokenize(x))\n",
    "\n",
    "df[\"summary\"] = df[\"summary\"].apply(lambda x : word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leolamoureux/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# REMOVE STOP WORDS\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df[\"article\"] = df[\"article\"].apply(lambda x: [w for w in x if not w in stop_words])\n",
    "\n",
    "df[\"summary\"] = df[\"summary\"].apply(lambda x: [w for w in x if not w in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/leolamoureux/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# LEMMATIZATION\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "df[\"article\"] = df[\"article\"].apply(lambda x: [WordNetLemmatizer().lemmatize(w) for w in x])\n",
    "\n",
    "df[\"summary\"] = df[\"summary\"].apply(lambda x: [WordNetLemmatizer().lemmatize(w) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
